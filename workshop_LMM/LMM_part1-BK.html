<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Linear Mixed-effects models (LMM) workshop</title>
    <meta charset="utf-8" />
    <meta name="author" content="Matteo Lisi" />
    <script src="libs/header-attrs-2.14/header-attrs.js"></script>
    <link rel="stylesheet" href="custom/style.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Linear Mixed-effects models (LMM) workshop
]
.subtitle[
## (Part 1)
]
.author[
### Matteo Lisi
]
.institute[
### Royal Holloway University of London
]
.date[
### TBC
]

---






# Today's program

&gt; 1. Multilevel models from a frequentist perspective
&gt; 2. The Bayesian approach
&gt; 3. Markov Chain Monte Carlo (MCMC)
&gt; 4. Examples

---

# Linear models

&gt; - The dependent variable `\(y\)` is modeled as a weighted combination of the independent variables, plus an additive error `\(\epsilon\)` 
`$$y_i=\beta_0 + \beta_1x_{1i} + \ldots +\beta_nx_{ni} + \epsilon_i \\
\epsilon \sim \mathcal{N}\left( 0, \sigma^2 \right)$$`

---

# Linear models

&gt; - The dependent variable `\(y\)` is modeled as a weighted combination of the independent variables, plus an additive error `\(\epsilon\)` 
`$$\textbf{Y} = \textbf{X}\beta + \epsilon \\
\epsilon \sim \mathcal{N}\left( 0, \sigma^2 \right)$$`

---- 

Matrix notation:

`$$\bf{Y} = \bf{X}\beta + \epsilon$$`
`$$\left( \begin{array}{c} y_1 \\ \vdots \\ y_m \end{array} \right) =
\left( \begin{array}{cccc} 
1 &amp; x_{11} &amp; \ldots &amp; x_{1n}\\ 
\vdots &amp; \vdots &amp; \vdots &amp; \vdots\\ 
1 &amp; x_{m1} &amp; \ldots &amp; x_{mn}
\end{array} \right)
\left( \begin{array}{c} \beta_0 \\  \beta_1 \\ \vdots \\ \beta_n \end{array} \right) +
\left( \begin{array}{c} \epsilon_1 \\ \vdots \\ \epsilon_m \end{array} \right)$$`

Matrix multiplication: 
`$$\left( \begin{array}{cc} a &amp; b \\ c&amp; d \end{array} \right) 
\left( \begin{array}{c} 1 \\ 2 \end{array} \right) = 
1 \left( \begin{array}{c} a \\ c \end{array} \right) + 
2 \left( \begin{array}{c} b \\ d \end{array} \right) =
\left( \begin{array}{c} a + 2b \\ c+ 2d \end{array} \right)$$`

---

## Linear mixed-effects models

- 'Classical' linear models are _fixed-effects_ only: 
    - independent variables are all experimental manipulation (they are not random).
    - the only random source of variation is the residual error `\(\epsilon \sim \mathcal{N}\left( 0, \sigma^2 \right)\)`.
- However _observations_ (e.g. trials) are often grouped according to _observational cluster_ (e.g. subjects), random samples from a larger population, on which we'd like to make inferences.
- In order to properly generalize from the sample to the population, these variables should be treated as _random effects_. Mixed-effects models allow to do that by explicitly modelling the population distribution.

----

- A model containing both fixed and random effects is usually called a _mixed-effects_ model (but also: hierarchical, multilevel, etc.).
- Random effects are treated as random variations around a population mean. These random variations are usually assumed to have a Gaussian distribution. 
- A simple example: a _random-intercept_ model. Regressions have the same slope in each of the `\(J\)` groups ($j=1,\dots,J$), but random variations in intercept $$y_{ij} = \beta_0 + b_j + \beta_1x_{ij} + \epsilon_{i}\\
\epsilon \sim \mathcal{N}\left( 0, \sigma^2 \right)\\
b \sim \mathcal{N}\left( 0, \sigma_b^2 \right)$$`

----

- General formulation in matrix notation
$$\textbf{Y} = \textbf{X}\beta + \textbf{Z}b + \epsilon $$
where `\(\textbf{X}\)` and `\(\textbf{Z}\)` are the known fixed-effects and random-effects regressor matrices.

- The components of the residual error vector `\(\epsilon \sim \mathcal{N}\left( 0, \sigma^2 \right)\)` are assumed to be *i.i.d.* (independent and identically distributed).

- The random-effect components, `\(b \sim \mathcal{N}\left( 0, \Omega \right)\)` are assumed to be normally distributed with mean 0, however they are not necessarily independent (the components `\(b_j\)` can be correlated, and correlations can be estimated). Example:$$\left[ {\begin{array}{c}
{{b_0}}\\
{{b_1}}
\end{array}} \right] \sim\cal N \left( {\left[ {\begin{array}{c}
0 \\ 0 \end{array}} \right],\Omega  = \left[ {\begin{array}{c}
{{\mathop{\rm Var}} \left( b_0 \right)} &amp; {{\mathop{\rm cov}} \left( {{b_0},{b_1}} \right)}\\
{{\mathop{\rm cov}} \left( {{b_0},{b_1}} \right)} &amp; {{\mathop{\rm Var}} \left( b_1 \right)}
\end{array}} \right]} \right)$$`
---

## Likelihood function

- Parameters ($\beta$, `\(\sigma^2\)` and `\(\Omega\)`) are estimated by maximizing the likelihood function, which is the probability of the data, given the parameters (but treated as a function of the parameters, keeping the data fixed).

- The probability of the data _conditional to the random effects_ is integrated with respect to the marginal density of the random effects, to obtain the marginal density of the data $$
L\left(\beta,\sigma^2,\Omega \mid \text{data}\right) = \int p \left(\text{data} \mid \beta,\sigma^2, b\right) \, p\left(b \mid \Omega\right) \, db
$$

---

## ML vs REML

- The `\(\textsf{R}\)` library `lme4` provides two methods for estimating parameters: Maximum Likelihood (ML) and Restricted Maximum Likelihood (REML).

- ML tend to be biased and underestimate the variance components (e.g. `\(\Omega\)`).

- REML provide less biased variance estimates: conceptually can be seen as similar to Bessel's correction for sample variance (using `\(n-1\)` instead of `\(n\)` in the denominator).

---

## Advantages of multilevel models 

- Improved estimates for _repeated sampling_ (e.g. repeated-measures design).
- Improved estimates for _imbalances in sampling_ (e.g. unequal number of trials across subjects).
- Avoid averaging (pre-averaging of data remove variation and can manifacture false confidence).
- Subject-specific standard error is taken into account in group-level estimates.
- Variation among group or individuals is modelled explicitly.
- Outperform classical methods in predictive ability.

## Example 1 `sleepstudy` {.build}

`sleepstudy` is a dataset in the `lme4` package, with reaction times data from 18 subjects that were restricted to 3 hours of sleep for 10 days. 

Questions:

&gt; - how reaction times changes with each sleep-deprived night?
- are individual difference in baseline response times related to individual differences in the effect of sleep deprivation?


```r
str(sleepstudy)
```

```
## 'data.frame':	180 obs. of  3 variables:
##  $ Reaction: num  250 259 251 321 357 ...
##  $ Days    : num  0 1 2 3 4 5 6 7 8 9 ...
##  $ Subject : Factor w/ 18 levels "308","309","310",..: 1 1 1 1 1 1 1 1 1 1 ...
```

----



&lt;div class="centered"&gt;


```
## `geom_smooth()` using formula 'y ~ x'
```

![](LMM_part1-BK_files/figure-html/unnamed-chunk-3-1.png)&lt;!-- --&gt;
&lt;/div&gt;

----

&gt; - The model we want to fit includes both random slopes and intercept $$
y_{ij} = \beta_0 + b_{0j} + \left( \beta_1 + b_{1j} \right) \times {\rm{Days}}_i + \epsilon_i \\
\epsilon \sim \mathcal{N}\left( 0, \sigma^2 \right) \\
b\sim\cal N \left( 0, \Omega\right)
$$

&gt; - In `lme4` 

```r
m.1 &lt;- lmer(Reaction ~ 1 + Days + (1 + Days|Subject), sleepstudy)
```

----


```r
summary(m.1)
```

```
## Linear mixed model fit by REML ['lmerMod']
## Formula: Reaction ~ 1 + Days + (1 + Days | Subject)
##    Data: sleepstudy
## 
## REML criterion at convergence: 1743.6
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -3.9536 -0.4634  0.0231  0.4634  5.1793 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev. Corr
##  Subject  (Intercept) 612.10   24.741       
##           Days         35.07    5.922   0.07
##  Residual             654.94   25.592       
## Number of obs: 180, groups:  Subject, 18
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept)  251.405      6.825  36.838
## Days          10.467      1.546   6.771
## 
## Correlation of Fixed Effects:
##      (Intr)
## Days -0.138
```

----

The function `confint()` allow easily to compute bootstrapped 95% CI of the parameters

```r
CI_fixef &lt;- confint(m.1, method="boot", nsim=50, oldNames=F)
```

```
## Computing bootstrap confidence intervals ...
```

```
## 
## 1 message(s): boundary (singular) fit: see help('isSingular')
```

```r
print(CI_fixef, digits=2)
```

```
##                               2.5 % 97.5 %
## sd_(Intercept)|Subject        12.80  37.44
## cor_Days.(Intercept)|Subject  -0.48   0.99
## sd_Days|Subject                2.66   8.36
## sigma                         22.27  28.94
## (Intercept)                  231.59 264.75
## Days                           6.78  14.86
```

## {.build}

- Tests of fixed and random effects can also be conducted using likelihood ratio tests, by comparing the likelihood of two _nested_ models.
- If `\(L_1\)` and `\(L_2\)` are the maximised likelihoods of two nested models with `\(k_1 &lt; k_2\)` parameters, the test statistic is `\(2\text{log}\left( L_2/ L_1 \right)\)`, which is approximately `\(\chi^2\)` with `\(k_2 - k_1\)` degrees of freedom.
- Example: test if there are substantial variation across subjects in the effect of `Days`

```r
# m.1 &lt;- lmer(Reaction ~ 1 + Days + (1 + Days|Subject), sleepstudy)
m.2 &lt;- lmer(Reaction ~ 1 + Days + (1 |Subject), sleepstudy)
anova(m.1, m.2)
```

```
## refitting model(s) with ML (instead of REML)
```

```
## Data: sleepstudy
## Models:
## m.2: Reaction ~ 1 + Days + (1 | Subject)
## m.1: Reaction ~ 1 + Days + (1 + Days | Subject)
##     npar    AIC    BIC  logLik deviance  Chisq Df Pr(&gt;Chisq)    
## m.2    4 1802.1 1814.8 -897.04   1794.1                         
## m.1    6 1763.9 1783.1 -875.97   1751.9 42.139  2  7.072e-10 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

----
_Shrinkage_: the _predicted_ `\({\hat b}_j\)` (conditional modes of the random effects) can be seen as a "compromise" between the within-subject estimates and the population mean.

&lt;div class="centered"&gt;
![](LMM_part1-BK_files/figure-html/unnamed-chunk-8-1.png)&lt;!-- --&gt;
&lt;/div&gt;

&lt;div class="notes"&gt;
They are sometime called BLUP (_Best Linear Umbiased Predictors_) since they are treated as random variables, not as unknown parameters, and in statistical jargon we say we _predict_ (rather than _estimate_) random variables. A more appropriate term is probably conditional modes of the random effects.
&lt;/div&gt;

---

## Diagnostic

As for any linear model, it is important to check that residual errors are well-behaved
&lt;div class="centered"&gt;
![](LMM_part1-BK_files/figure-html/unnamed-chunk-9-1.png)&lt;!-- --&gt;
&lt;/div&gt;
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
